import sys
import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import monai
from monai.data import DataLoader
import torch
from torch.autograd import Variable
from torchsummary import summary
from torch.optim.lr_scheduler import ReduceLROnPlateau

class DeepPETModelManager:
    def __init__(self, model, odir, checkpoint:str=None) -> None:

        cuda_available = torch.cuda.is_available()
        mps_available = torch.backends.mps.is_available()
        print(f"GPU available: {(cuda_available | mps_available)}")
        if mps_available:
            self.device = 'mps'
        elif cuda_available:
            self.device = 'cuda'
        else:
            self.device = 'cpu'

        self.odir = odir
        if not os.path.isdir(self.odir):
            os.mkdir(self.odir)

        self.checkpoint = checkpoint
        self.model = model.to(self.device)

        self.optimizer = None
        self.current_epoch = None

        pass

    def create_loader(self, ds, batch_size, shuffle=True):

        loader = DataLoader(
            ds,
            batch_size=batch_size,
            shuffle=shuffle,
            collate_fn=monai.data.utils.pad_list_data_collate,
            persistent_workers=False,
        )

        return loader

    def load_checkpoint(self, ft=False):

        print(f"loading checkpoint from {self.checkpoint}")

        model_checkpoint = torch.load(self.checkpoint, map_location=self.device)
        self.model.load_state_dict(model_checkpoint["model"])

        if ft:
            # Resume training from last checkpoint
            self.optimizer.load_state_dict(model_checkpoint["optimizer"])
            self.current_epoch = model_checkpoint["epoch"]

        return self.model

    def train_model(self, train_ds, val_ds, loss_function, num_epochs, optimizer, batch_size):
        timestr = time.strftime("%Y%m%d-%H%M%S")

        if self.checkpoint is not None:
            self.model = self.load_checkpoint(ft=True)

            # create new checkpoint for ft model
            self.checkpoint = os.path.join(self.odir, f"{os.path.splitext(os.path.basename(self.checkpoint))[0]}_ft.pth")

            print(f'Finetuning from epoch: {self.current_epoch}')
        else:
            self.checkpoint = os.path.join(self.odir, f"model_{timestr}.pth")

        self.history = os.path.join(self.odir, f"history_{timestr}.csv")

        self.loss_function = loss_function
        self.num_epochs = num_epochs
        self.optimizer = optimizer
        self.batch_size = batch_size

        if self.checkpoint is not None:
            print(f'Finetuning from epoch: {self.current_epoch}')
            start_epoch = self.current_epoch
        else:
            self.checkpoint = os.path.join(self.odir, f"model_{timestr}.pth")
            start_epoch = 0

        self.history = os.path.join(self.odir, f"history_{timestr}.csv")
        total_epochs = start_epoch + self.num_epochs

        print(f"batch_size: {self.batch_size}")

        scheduler = ReduceLROnPlateau(self.optimizer, mode='min', patience=10, factor=0.5)

        train_steps = np.floor(len(train_ds) / self.batch_size)
        val_steps = np.floor(len(val_ds) / self.batch_size)
        train_loader = self.create_loader(train_ds, batch_size=self.batch_size)
        val_loader = self.create_loader(val_ds, batch_size=self.batch_size)

        epoch_train_loss_values = list()
        epoch_train_accuracy_values = list()
        epoch_val_loss_values = list()
        epoch_val_accuracy_values = list()

        if self.loss_function.pos_weight is not None:
            self.loss_function.pos_weight = self.loss_function.pos_weight.to(self.device)

        for epoch in range(start_epoch, total_epochs + 1):

            start_time = time.time()
            print("-" * 10)
            print(f"epoch {epoch}/{total_epochs}")
            epoch_loss = 0
            epoch_accuracy = 0

            # initialize train and valdiation and iterator 
            train_loader_iter = iter(train_loader)
            val_loader_iter = iter(val_loader)
     
            self.model.train()
            for step in np.arange(train_steps):
                batch_data = next(train_loader_iter)
                
                inputs, labels = batch_data["img"].to(self.device), batch_data["label"].to(self.device)

                self.optimizer.zero_grad()
                outputs = self.model(inputs)

                loss = self.loss_function(outputs.float(), labels.unsqueeze(1).float())
                loss.backward()
                self.optimizer.step()

                epoch_loss += loss.item()
                print(f"{int(step+1)}/{int(train_steps)} step train loss: {loss.item():.4f}")

                # positivity threshold = 0 due to lack of final sigmoid layer
                pred = outputs.float() > 0 
                epoch_accuracy += (pred == labels.unsqueeze(1).float()).sum().item() / labels.shape[0]

            epoch_accuracy /= train_steps
            epoch_loss /= train_steps
            epoch_train_loss_values.append(epoch_loss)
            epoch_train_accuracy_values.append(epoch_accuracy)
            print(f"\n{epoch}/{total_epochs}, train loss: {epoch_loss:.4f}, train accuracy: {epoch_accuracy:.4f}\n")
            print(f"epoch time elapsed: {time.time() - start_time}")

            self.model.eval()
            with torch.no_grad():
                epoch_val_loss = 0
                epoch_val_accuracy = 0
                
                for step in np.arange(val_steps):
                    val_data = next(val_loader_iter)
                    val_inputs, val_labels = val_data["img"].to(self.device), val_data["label"].to(self.device)
                    val_outputs = self.model(val_inputs)
                    val_loss = self.loss_function(val_outputs.float(), val_labels.unsqueeze(1).float())
                    epoch_val_loss += val_loss.item()

                    val_pred = val_outputs.float() > 0
                    epoch_val_accuracy += (val_pred == val_labels.unsqueeze(1).float()).sum().item() / val_labels.shape[0] 

                epoch_val_accuracy /= val_steps
                epoch_val_loss /= val_steps
                print(f"\n{epoch}/{total_epochs}, validation loss: {epoch_val_loss:.4f}, validation accuracy: {epoch_val_accuracy:.4f}\n")
                epoch_val_loss_values.append(epoch_val_loss)
                epoch_val_accuracy_values.append(epoch_val_accuracy)

                scheduler.step(epoch_val_loss)

            # save models
            torch.save({"epoch": epoch + 1, "model": self.model.state_dict(), "optimizer": self.optimizer.state_dict()}, self.checkpoint)

            # save training log
            log_dict = {
                "train_loss": epoch_train_loss_values,
                "train_accuracy": epoch_train_accuracy_values,
                "val_loss": epoch_val_loss_values,
                "val_accuracy": epoch_val_accuracy_values,
            }

            history_df = pd.DataFrame(log_dict)
            history_df.to_csv(self.history, index=False)

            # early stopping
            epoch_val_lss_values_arr = np.array(epoch_val_loss_values)
            min_idx = np.where(epoch_val_lss_values_arr == epoch_val_lss_values_arr.min())[0][0]
            if epoch >= 25 + start_epoch and min_idx < len(epoch_val_lss_values_arr) - 25:
                return self.model

        return self.model

    def plot_history(self):

        hist_df = pd.read_csv(self.history)

        plt.figure()
        plt.plot(range(len(hist_df)), hist_df["train_loss"], label="training")
        plt.plot(range(len(hist_df)), hist_df["val_loss"], label="validation")
        plt.xlabel("epoch")
        plt.ylabel("loss")
        plt.legend()
        plt.savefig(os.path.join(self.odir, "loss.png"), dpi=300)
        plt.close()

        plt.figure()
        plt.plot(range(len(hist_df)), hist_df["train_accuracy"], label="training")
        plt.plot(range(len(hist_df)), hist_df["val_accuracy"], label="validation")
        plt.xlabel("epoch")
        plt.ylabel("accuracy")
        plt.legend()
        plt.savefig(os.path.join(self.odir, "accuracy.png"), dpi=300)
        plt.close()

        return None

    def predict(self, test_ds):

        self.load_checkpoint()
        self.model.eval()
        test_loader = self.create_loader(test_ds, batch_size=1, shuffle=False)

        outputs = np.empty((len(test_ds),))
        outputs[:] = np.NaN

        try:
            for i, test_batch in enumerate(test_loader):
                try:
                    test_img = test_batch["img"].to(self.device)
                    test_outputs = self.model(test_img)
                    test_outputs = test_outputs.flatten().detach()
                    outputs[i] = test_outputs.flatten().detach()
                    print(f"making predictions: {i+1}/{len(test_ds)} â€“  {outputs[i]}")

                except Exception:
                    print(f"making predictions: {i+1}/{len(test_ds)} â€“  failed")
            return outputs
        except Exception:
            print('failed')
            return outputs

    def generate_saliency_maps(self, img):

        self.model.eval()
        self.model.zero_grad()

        img = img.to(self.device)
        print(f"input image shape: {img.shape}")

        img = Variable(img, requires_grad=True)
        suvr = self.model(img)
        suvr.backward()

        gradients = self.model.get_input_gradient()

        return gradients

    def generate_smooth_grad(self, img, n=50):

        smooth_grad = np.zeros(img.shape)
        img_np = img.detach().cpu().numpy()
        stdev = 0.10 * (np.max(img_np) - np.min(img_np))
        print(stdev)

        for i in np.arange(n):

            print(img.shape)
            img_w_noise = img + np.random.normal(0, stdev, img.shape).astype(np.float32)
            print(img_w_noise.shape)
            grad = self.generate_saliency_maps(img_w_noise)
            print(grad.shape)
            smooth_grad += grad
            print(smooth_grad.shape)

        smooth_grad = smooth_grad / n

        return smooth_grad

    def generate_grad_cam(self, img):
        """
        compute GradCAM for ONLY ONE image at different depths of the model
        """

        self.load_checkpoint()

        self.model.eval()
        self.model.zero_grad()
        img = img.to(self.device)
        print(f"input image shape: {img.shape}")
        output = self.model(img)
        output.backward()

        gradient_maps = self.model.get_activation_gradients()
        print(f"dimension of gradient maps: {gradient_maps.shape}")
        activation_maps = self.model.get_activation_maps(img)
        print(f"dimension of activation maps: {activation_maps.shape}")
        grad_cam = self.compute_gradcam(activation_maps, gradient_maps)
        print(f"dimension of GradCAM before resizing: {grad_cam.shape}")

        return activation_maps, gradient_maps, grad_cam

    def compute_gradcam(self, activation_maps, gradient_maps):

        averaged_gradients = torch.mean(gradient_maps, dim=[0, 2, 3, 4])
        # print(averaged_gradients.shape)
        for i in range(activation_maps.shape[1]):
            activation_maps[:, i, :, :, :] *= averaged_gradients[i]
        grad_cam = torch.mean(activation_maps, dim=1).squeeze().detach().cpu()
        # ReLU
        grad_cam = np.maximum(grad_cam, 0)
        grad_cam /= torch.max(grad_cam)

        return grad_cam
    
    def fetch_model(self):

        self.load_checkpoint()
        self.model.eval()
        
        return self.model

    def summary(self, input_shape):

        # Saving the reference of the standard output
        original_stdout = sys.stdout

        with open(os.path.join(self.odir, "model.txt"), "w") as f:
            sys.stdout = f
            summary(self.model, input_shape)
            # Reset the standard output
            sys.stdout = original_stdout

        return None


